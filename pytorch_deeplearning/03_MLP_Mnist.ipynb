{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cuda'\n",
    "else:\n",
    "    DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST DATA Download & train test split\n",
    "# root 저장될 공간, train 훈련데이터 여부, download 다운로드 여부, transform 다운과 동시에 데이터 전처리 가능\n",
    "# transforms.ToTensor() torch모델로 집어넣기 때문에 torch.Tensor로 변환시켜주고, \n",
    "# 동시에 너무 큰 값을 갖는 데이터는 불안정하거나 과적합되는 방향으로 진행될 가능성이 있기때문에 0~1사이의 값을 갖는 정규화 진행\n",
    "train_dataset = datasets.MNIST(root = './Data/MNIST',train = True,download = True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST(root = './Data/MNIST',train = False,download = True, transform=transforms.ToTensor())\n",
    "\n",
    "# 다운로드한 dataset들을 배치사이즈로 분리해 지정한다. 즉, 배치사이즈 만큼의 미니배치를 구성하는 것을 DataLoader를 통해 할 수 있다.\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for (x_train,y_train) in train_loader:\n",
    "    print(x_train.size())\n",
    "    print(y_train.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :  torch.Size([32, 1, 28, 28])  type :  torch.FloatTensor\n",
      "y_train :  torch.Size([32])  type :  torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인해보기\n",
    "for (x_train,y_train) in train_loader:\n",
    "    print('X_train : ',x_train.size(), ' type : ',x_train.type())\n",
    "    print('y_train : ',y_train.size(), ' type : ',y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 확인해보기 (2)\n",
    "pltsize = 1\n",
    "plt.figure(figsize=(10*pltsize, pltsize))\n",
    "for i in range(10):\n",
    "    plt.subplot(1,10,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(x_train[i,:,:,:].numpy().reshape(28,28), cmap = 'gray_r')\n",
    "    plt.title('Class : ' + str(y_train[i].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP 모델 설계하기\n",
    "class MNIST_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        # nn.Module의 메소드 상속\n",
    "        super(MNIST_Model,self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28,512)\n",
    "        self.fc2 = nn.Linear(512,256)\n",
    "        self.fc3 = nn.Linear(256,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = x.view(-1,28*28)\n",
    "        x = self.fc1(x)\n",
    "        # torch model 설계에 유용한 함수들을 모아놓은 torch.nn.functional\n",
    "        x = F.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.sigmoid(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST_Model(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# model 을 cuda 에 할당\n",
    "model = MNIST_Model().to(DEVICE)\n",
    "# loss값들을 최소화하는 방법으로 SGD를 선택했고, 가중치를 업데이트하는 것은 model.parameters(), 학습률은 0.01, 옵티마이저 관성 : 0.5로 설정\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = 0.01, momentum=0.5)\n",
    "# 원핫인코딩\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP 모델 학습을 진행하며 학습 데이터에 대한 모델 성능을 확인하는 함수 정의\n",
    "def train(model, train_loader, optimizer, log_interval):\n",
    "    # 기존에 정의한 모델을 학습상태로 지정\n",
    "    model.train()\n",
    "    for batch_idx, (image,label) in enumerate(train_loader):\n",
    "        # 기존에 정의한 장비에 할당\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "\n",
    "        # 기존에 정의한 장비에 이미지 데이터와 레이블 데이터를 할당할 경우, 과거에 이용한 loss의 gradient가 optimizer에 할당되어 있으므로 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 장비에 할당한 이미지 데이터를 MLP 모델의 Input값으로 넣어 예측\n",
    "        output = model(image)\n",
    "\n",
    "        # 계산된 Output과 장비에 할당된 레이블 데이터를 기존에 정의한 CrossEntropy를 이용해 Loss값을 계산\n",
    "        loss = criterion(output,label)\n",
    "\n",
    "        # loss값을 계산한 결과를 바탕으로 Back Propagation 을 통해 계산된 Gradient 값을 각 파라미터에 할당\n",
    "        loss.backward()\n",
    "\n",
    "        # 각 파라미터에 할당된 Gradient값을 이용해 파라미터 값을 업데이트한다.\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch : {} [{}/{} ({:.0f}%)]\\t Train Loss : {:.6f}\".format(Epoch,batch_idx*len(image),len(train_loader.dataset),100. * batch_idx / len(train_loader),loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 데이터에 대한 모델 성능을 확인하는 함수\n",
    "def evaluate(model,test_loader):\n",
    "    # 이미 학습이 완료가 된 모델에 대해 더 이상 학습을 통해 파라미터가 진행되는 상태가 아닌, 평가 상태로 지정\n",
    "    model.eval()\n",
    "\n",
    "    # test_loss 값을 계산하기 위해 초기화\n",
    "    test_loss = 0\n",
    "    # 올바르게 분류한 경우를 세기 위해 correct 변수 초기화\n",
    "    correct = 0\n",
    "    \n",
    "    # gradient를 통해 파라미터 값이 업데이트되는 현상을 방지하기 위해 torch.no_grad를 사용해 흐름을 억제한다.\n",
    "    with torch.no_grad():\n",
    "        # test image , label를 뽑아냄\n",
    "        for image, label in test_loader:\n",
    "            # 이미지, 라벨을 cuda 에 할당\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "\n",
    "            # image를 모델에 넣어 예측 > 결과값\n",
    "            output = model(image)\n",
    "\n",
    "            # crossentropy 객체에 output값과 라벨 값을 넣어주고 test_loss에 더해준다.\n",
    "            test_loss += criterion(output,label).item()\n",
    "\n",
    "            # 결과값은 크기가 10인 벡터값이니 가장 큰값의 위치에 대해 대응하는 클래스로 예측했다고 판단\n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "\n",
    "            # 예측값과 실제 라벨값이 일치하게 되면 correct에 더해준다.\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "    \n",
    "    # test_loss 의 값을 데이터 크기 만큼 나눠서 평균값을 구한다.\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    # 데이터 크기 만큼 나눠 평균값을 구한다.\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    \n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch : 1 [0/60000 (0%)]\t Train Loss : 2.352414\n",
      "Train Epoch : 1 [6400/60000 (11%)]\t Train Loss : 2.259543\n",
      "Train Epoch : 1 [12800/60000 (21%)]\t Train Loss : 2.291816\n",
      "Train Epoch : 1 [19200/60000 (32%)]\t Train Loss : 2.289183\n",
      "Train Epoch : 1 [25600/60000 (43%)]\t Train Loss : 2.310908\n",
      "Train Epoch : 1 [32000/60000 (53%)]\t Train Loss : 2.279367\n",
      "Train Epoch : 1 [38400/60000 (64%)]\t Train Loss : 2.297324\n",
      "Train Epoch : 1 [44800/60000 (75%)]\t Train Loss : 2.284940\n",
      "Train Epoch : 1 [51200/60000 (85%)]\t Train Loss : 2.299412\n",
      "Train Epoch : 1 [57600/60000 (96%)]\t Train Loss : 2.277715\n",
      "\\[EPOCH : 1], \tTest Loss : 0.0696, \tTest Accuracy : 28.62 %\n",
      "\n",
      "Train Epoch : 2 [0/60000 (0%)]\t Train Loss : 2.208535\n",
      "Train Epoch : 2 [6400/60000 (11%)]\t Train Loss : 2.205148\n",
      "Train Epoch : 2 [12800/60000 (21%)]\t Train Loss : 2.173249\n",
      "Train Epoch : 2 [19200/60000 (32%)]\t Train Loss : 2.133495\n",
      "Train Epoch : 2 [25600/60000 (43%)]\t Train Loss : 2.042274\n",
      "Train Epoch : 2 [32000/60000 (53%)]\t Train Loss : 1.924998\n",
      "Train Epoch : 2 [38400/60000 (64%)]\t Train Loss : 1.740543\n",
      "Train Epoch : 2 [44800/60000 (75%)]\t Train Loss : 1.340151\n",
      "Train Epoch : 2 [51200/60000 (85%)]\t Train Loss : 1.514390\n",
      "Train Epoch : 2 [57600/60000 (96%)]\t Train Loss : 1.418793\n",
      "\\[EPOCH : 2], \tTest Loss : 0.0386, \tTest Accuracy : 62.83 %\n",
      "\n",
      "Train Epoch : 3 [0/60000 (0%)]\t Train Loss : 1.435920\n",
      "Train Epoch : 3 [6400/60000 (11%)]\t Train Loss : 1.232359\n",
      "Train Epoch : 3 [12800/60000 (21%)]\t Train Loss : 0.863312\n",
      "Train Epoch : 3 [19200/60000 (32%)]\t Train Loss : 1.164876\n",
      "Train Epoch : 3 [25600/60000 (43%)]\t Train Loss : 0.938893\n",
      "Train Epoch : 3 [32000/60000 (53%)]\t Train Loss : 1.216183\n",
      "Train Epoch : 3 [38400/60000 (64%)]\t Train Loss : 0.879808\n",
      "Train Epoch : 3 [44800/60000 (75%)]\t Train Loss : 0.752610\n",
      "Train Epoch : 3 [51200/60000 (85%)]\t Train Loss : 0.573741\n",
      "Train Epoch : 3 [57600/60000 (96%)]\t Train Loss : 1.093946\n",
      "\\[EPOCH : 3], \tTest Loss : 0.0233, \tTest Accuracy : 77.43 %\n",
      "\n",
      "Train Epoch : 4 [0/60000 (0%)]\t Train Loss : 0.646321\n",
      "Train Epoch : 4 [6400/60000 (11%)]\t Train Loss : 0.646977\n",
      "Train Epoch : 4 [12800/60000 (21%)]\t Train Loss : 0.737141\n",
      "Train Epoch : 4 [19200/60000 (32%)]\t Train Loss : 0.873167\n",
      "Train Epoch : 4 [25600/60000 (43%)]\t Train Loss : 0.443778\n",
      "Train Epoch : 4 [32000/60000 (53%)]\t Train Loss : 0.496790\n",
      "Train Epoch : 4 [38400/60000 (64%)]\t Train Loss : 0.660810\n",
      "Train Epoch : 4 [44800/60000 (75%)]\t Train Loss : 0.622823\n",
      "Train Epoch : 4 [51200/60000 (85%)]\t Train Loss : 0.716655\n",
      "Train Epoch : 4 [57600/60000 (96%)]\t Train Loss : 0.661651\n",
      "\\[EPOCH : 4], \tTest Loss : 0.0178, \tTest Accuracy : 83.61 %\n",
      "\n",
      "Train Epoch : 5 [0/60000 (0%)]\t Train Loss : 0.594919\n",
      "Train Epoch : 5 [6400/60000 (11%)]\t Train Loss : 0.542139\n",
      "Train Epoch : 5 [12800/60000 (21%)]\t Train Loss : 0.507891\n",
      "Train Epoch : 5 [19200/60000 (32%)]\t Train Loss : 0.414685\n",
      "Train Epoch : 5 [25600/60000 (43%)]\t Train Loss : 0.496755\n",
      "Train Epoch : 5 [32000/60000 (53%)]\t Train Loss : 0.253371\n",
      "Train Epoch : 5 [38400/60000 (64%)]\t Train Loss : 0.416929\n",
      "Train Epoch : 5 [44800/60000 (75%)]\t Train Loss : 0.684093\n",
      "Train Epoch : 5 [51200/60000 (85%)]\t Train Loss : 0.562805\n",
      "Train Epoch : 5 [57600/60000 (96%)]\t Train Loss : 0.631631\n",
      "\\[EPOCH : 5], \tTest Loss : 0.0145, \tTest Accuracy : 86.18 %\n",
      "\n",
      "Train Epoch : 6 [0/60000 (0%)]\t Train Loss : 0.305969\n",
      "Train Epoch : 6 [6400/60000 (11%)]\t Train Loss : 0.306587\n",
      "Train Epoch : 6 [12800/60000 (21%)]\t Train Loss : 0.297498\n",
      "Train Epoch : 6 [19200/60000 (32%)]\t Train Loss : 0.627533\n",
      "Train Epoch : 6 [25600/60000 (43%)]\t Train Loss : 0.384594\n",
      "Train Epoch : 6 [32000/60000 (53%)]\t Train Loss : 0.371753\n",
      "Train Epoch : 6 [38400/60000 (64%)]\t Train Loss : 0.382017\n",
      "Train Epoch : 6 [44800/60000 (75%)]\t Train Loss : 0.415553\n",
      "Train Epoch : 6 [51200/60000 (85%)]\t Train Loss : 0.389920\n",
      "Train Epoch : 6 [57600/60000 (96%)]\t Train Loss : 0.414692\n",
      "\\[EPOCH : 6], \tTest Loss : 0.0130, \tTest Accuracy : 87.79 %\n",
      "\n",
      "Train Epoch : 7 [0/60000 (0%)]\t Train Loss : 0.569956\n",
      "Train Epoch : 7 [6400/60000 (11%)]\t Train Loss : 0.307874\n",
      "Train Epoch : 7 [12800/60000 (21%)]\t Train Loss : 0.396119\n",
      "Train Epoch : 7 [19200/60000 (32%)]\t Train Loss : 0.490706\n",
      "Train Epoch : 7 [25600/60000 (43%)]\t Train Loss : 0.411275\n",
      "Train Epoch : 7 [32000/60000 (53%)]\t Train Loss : 0.305208\n",
      "Train Epoch : 7 [38400/60000 (64%)]\t Train Loss : 0.447717\n",
      "Train Epoch : 7 [44800/60000 (75%)]\t Train Loss : 0.373623\n",
      "Train Epoch : 7 [51200/60000 (85%)]\t Train Loss : 0.338788\n",
      "Train Epoch : 7 [57600/60000 (96%)]\t Train Loss : 0.328160\n",
      "\\[EPOCH : 7], \tTest Loss : 0.0121, \tTest Accuracy : 88.52 %\n",
      "\n",
      "Train Epoch : 8 [0/60000 (0%)]\t Train Loss : 0.197887\n",
      "Train Epoch : 8 [6400/60000 (11%)]\t Train Loss : 0.795321\n",
      "Train Epoch : 8 [12800/60000 (21%)]\t Train Loss : 0.255248\n",
      "Train Epoch : 8 [19200/60000 (32%)]\t Train Loss : 0.189241\n",
      "Train Epoch : 8 [25600/60000 (43%)]\t Train Loss : 0.237060\n",
      "Train Epoch : 8 [32000/60000 (53%)]\t Train Loss : 0.244778\n",
      "Train Epoch : 8 [38400/60000 (64%)]\t Train Loss : 0.325788\n",
      "Train Epoch : 8 [44800/60000 (75%)]\t Train Loss : 0.339650\n",
      "Train Epoch : 8 [51200/60000 (85%)]\t Train Loss : 0.344632\n",
      "Train Epoch : 8 [57600/60000 (96%)]\t Train Loss : 0.619243\n",
      "\\[EPOCH : 8], \tTest Loss : 0.0114, \tTest Accuracy : 89.37 %\n",
      "\n",
      "Train Epoch : 9 [0/60000 (0%)]\t Train Loss : 0.449382\n",
      "Train Epoch : 9 [6400/60000 (11%)]\t Train Loss : 0.277328\n",
      "Train Epoch : 9 [12800/60000 (21%)]\t Train Loss : 0.497503\n",
      "Train Epoch : 9 [19200/60000 (32%)]\t Train Loss : 0.177331\n",
      "Train Epoch : 9 [25600/60000 (43%)]\t Train Loss : 0.343710\n",
      "Train Epoch : 9 [32000/60000 (53%)]\t Train Loss : 0.524248\n",
      "Train Epoch : 9 [38400/60000 (64%)]\t Train Loss : 0.392611\n",
      "Train Epoch : 9 [44800/60000 (75%)]\t Train Loss : 0.558873\n",
      "Train Epoch : 9 [51200/60000 (85%)]\t Train Loss : 0.296165\n",
      "Train Epoch : 9 [57600/60000 (96%)]\t Train Loss : 0.174988\n",
      "\\[EPOCH : 9], \tTest Loss : 0.0109, \tTest Accuracy : 89.97 %\n",
      "\n",
      "Train Epoch : 10 [0/60000 (0%)]\t Train Loss : 0.387005\n",
      "Train Epoch : 10 [6400/60000 (11%)]\t Train Loss : 0.355990\n",
      "Train Epoch : 10 [12800/60000 (21%)]\t Train Loss : 0.262197\n",
      "Train Epoch : 10 [19200/60000 (32%)]\t Train Loss : 0.447581\n",
      "Train Epoch : 10 [25600/60000 (43%)]\t Train Loss : 0.520918\n",
      "Train Epoch : 10 [32000/60000 (53%)]\t Train Loss : 0.158686\n",
      "Train Epoch : 10 [38400/60000 (64%)]\t Train Loss : 0.177948\n",
      "Train Epoch : 10 [44800/60000 (75%)]\t Train Loss : 0.454687\n",
      "Train Epoch : 10 [51200/60000 (85%)]\t Train Loss : 0.444990\n",
      "Train Epoch : 10 [57600/60000 (96%)]\t Train Loss : 0.389938\n",
      "\\[EPOCH : 10], \tTest Loss : 0.0105, \tTest Accuracy : 90.29 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## MLP 학습을 실행하면서 Train, Test_set 의 Loss 및 Test set Accuracy 를 확인하기\n",
    "for Epoch in range(1,EPOCHS+1):\n",
    "    train(model, train_loader, optimizer, log_interval=200)\n",
    "    test_loss, test_accuracy = evaluate(model,test_loader)\n",
    "    print(\"\\[EPOCH : {}], \\tTest Loss : {:.4f}, \\tTest Accuracy : {:.2f} %\\n\".format(Epoch, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c3a6afb4ca1356324ac719a8f4904d3d9af325fac862a66ccc73b4ecb2536197"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('torch1.7': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
