{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Transfer Learning\n",
    "- 예를 들어 강아지와 고양이를 구분하는 딥러닝 모델을 구축하고자 한다.\n",
    "- 데이터가 100장밖에 없다면 미리 학습해 놓은 Pre_trained model을 가져와 fine tuning 을 시켜야한다.\n",
    "> 이러한 방법을 Transfer Learning 이라고 한다. == 전이학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 일반적인 방법론\n",
    "- 보통 학습되어 있는 pretrained model은 훨씬 큰 문제를 푸는 모델이기 때문에 output layer를 수정해야 한다.\n",
    "- 그리고 우리가 보유한 데이터를 input으로 학습을 진행해야한다.\n",
    "- 일반적으로 pre trained model 의 fc layer는 이전의 weight 는 학습시키지 않는다. == weight freezing이라고 표현\n",
    "- 다시말해 fc layer 이전에 weight 들은 freezing을 시켜놓고 우리의 데이터를 통해 fc layer 의 weight 만 학습을 시킨다는 말이다.\n",
    "- 이 과정을 fine tuning 이라고 한다.\n",
    "- Transfer Learning은 Initialization 의 개념으로도 볼 수 있다. parameter 들의 초기값을 우리는 특정 기법을 쓰는 것이 아닌 Pre_trained model의 가중치들을 사용\n",
    "- 일반적으로 데이터가 많지 않은 상황에서 보유한 데이터만으로 학습시킨 것보다 전이학습을 한 경우에서 모델 성능이 높고, 학습을 더 빠르게 시킬 수 있다는 장점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version : 1.7.1+cu110\n",
      "torch cuda Device : cuda\n",
      "batch_size : 32\n",
      "Epochs : 20\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cuda'\n",
    "else:\n",
    "    DEVICE = 'cpu'\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "\n",
    "print('torch version : {}'.format(torch.__version__))\n",
    "print('torch cuda Device : {}'.format(DEVICE))\n",
    "print('batch_size : {}\\nEpochs : {}'.format(BATCH_SIZE,EPOCHS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train' : transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
    "    ]),\n",
    "    'val' : transforms.Compose([\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.Resize(256),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n",
    "    ])\n",
    "}\n",
    "\n",
    "train_datasets = datasets.ImageFolder(\"./data/hymenoptera_data\",transforms = data_transforms['train'])\n",
    "test_datasets = datasets.ImageFolder(\"./data/hymenoptera_data\",transforms = data_transforms['val'])\n",
    "image_datasets = {x : datasets.ImageFolder(\"./data/hymenoptera_data\",data_transforms[x]) for x in ['train','val']}\n",
    "dataloader = {x : torch.utils.data.DataLoader(image_datasets[x], batch_size = BATCH_SIZE, num_workers = 0, shuffle = True) for x in ['train','val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset ImageFolder\n",
       "     Number of datapoints: 397\n",
       "     Root location: ./data/hymenoptera_data\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)\n",
       "                RandomHorizontalFlip(p=0.5)\n",
       "                ToTensor()\n",
       "                Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
       "            ),\n",
       " 'val': Dataset ImageFolder\n",
       "     Number of datapoints: 397\n",
       "     Root location: ./data/hymenoptera_data\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                CenterCrop(size=(224, 224))\n",
       "                Resize(size=256, interpolation=PIL.Image.BILINEAR)\n",
       "                ToTensor()\n",
       "                Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
       "            )}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for a,b in dataloader['train']:\n",
    "    print(a.size())\n",
    "    print(b.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c3a6afb4ca1356324ac719a8f4904d3d9af325fac862a66ccc73b4ecb2536197"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('torch1.7': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
